#!/usr/bin/python3
import numpy as np
from argparse import ArgumentParser
import pandas as pd
import redis
import time, os, sys
from collections import namedtuple, defaultdict
from smclocalize import *
import firebase_admin
from firebase_admin import firestore
import pytz
import sensei


ModelState = namedtuple("ModelState", "x_discrete_particles x_continuous_particles log_weights")

class ConfigError(ValueError):
    pass


class LocationModelWorker:
    def __init__(self, classroom_id, num_particles):
        self.classroom_id = classroom_id
        self.num_particles = num_particles

        redis_url = os.getenv('REDIS_URL')
        if redis_url is None:
            raise ConfigError("Missing environment variable REDIS_URL. Please see README.")
        self.redis_handle = redis.Redis.from_url(redis_url)
        self.input_queue = 'radio_obs_classroom_%d' % self.classroom_id

        firebase_url = os.getenv('FIREBASE_URL')
        if firebase_url is None:
            raise ConfigError("Missing environment variable FIREBASE_URL. Please see README.")

        credentials_certificate = firebase_admin.credentials.Certificate({
            'private_key': os.getenv('FIREBASE_PRIVATE_KEY', False),
            'client_email': os.getenv('FIREBASE_CLIENT_EMAIL', ''),
            'type': 'service_account',
            'token_uri': 'https://accounts.google.com/o/oauth2/token',
            'project_id': os.getenv('FIREBASE_PROJECT_ID', 'sensei-b9fb6'),
            'private_key_id': os.getenv('FIREBASE_PRIVATE_KEY_ID'),
            'client_id': os.getenv('FIREBASE_CLIENT_ID'),
            'auth_uri': 'https://accounts.google.com/o/oauth2/auth',
            'token_uri': 'https://accounts.google.com/o/oauth2/token',
            'auth_provider_x509_cert_url': 'https://www.googleapis.com/oauth2/v1/certs',
            'client_x509_cert_url': os.getenv('FIREBASE_CLIENT_X509_CERT_URL')
            })
        firebase_admin.initialize_app(credentials_certificate, options={
            'databaseURL': firebase_url
        })
        self.firebase = firebase_admin.firestore.client();


        #Room geometry
        # TODO: fetch from firebase
        feet_to_meters = 12*2.54/100
        room_size = np.array([(19.0 + 4.0/12.0 + 15.0/12.0 + 43.0 + 2.0/12.0 + 2.0)*feet_to_meters,
                              (11.0 + 9.0/12.0)*feet_to_meters])
        print("room_size = %s" % room_size)
        room_corners = np.array([[0.0, 0.0], room_size])
        print("room_corners = %s" % room_corners)


        sensei_api = sensei.Api(username=os.getenv('SENSEI_USERNAME'), password=os.getenv('SENSEI_PASSWORD'))
        mappings = sensei_api.get_sensor_mappings(classroom_id)
        entities = defaultdict(list)
        for mapping in mappings:
            entities[mapping.entity_type.value].append(mapping)

        child_entity_ids = [entity.entity_id for entity in entities['child']]
        material_entity_ids = [entity.entity_id for entity in entities['material']]
        teacher_entity_ids = [entity.entity_id for entity in entities['teacher']]
        area_entity_ids = [entity.entity_id for entity in entities['area']]

        print("child_entity_ids = %s" % child_entity_ids)
        print("material_entity_ids = %s" % material_entity_ids)
        print("teacher_entity_ids = %s" % teacher_entity_ids)
        print("area_entity_ids = %s" % area_entity_ids)

        self.entity_ids = (
            [['child', id] for id in child_entity_ids] +
            [['material', id] for id in material_entity_ids] +
            [['teacher', id] for id in teacher_entity_ids] +
            [['area', id] for id in area_entity_ids])

        self.variable_structure = SensorVariableStructure(child_entity_ids,
                                                          material_entity_ids,
                                                          teacher_entity_ids,
                                                          area_entity_ids)

        areas_by_id = {area.entity_id: area for area in sensei_api.get_areas(classroom_id)}

        area_positions = []

        room_center = room_size / 2
        for area_id in area_entity_ids:
            area = areas_by_id.get(area_id)
            if area and area.position_x and area.position_y:
                position = [area.position_x, area.position_y]
            else:
                position = room_center
            area_positions.append(position)

        fixed_sensor_positions = np.array(area_positions)
        print("fixed_sensor_positions = %s" % fixed_sensor_positions)

        self.sensor_model = SensorModel(
            self.variable_structure,
            room_corners,
            fixed_sensor_positions,
            self.num_particles)


    def run(self):
        self.model_state = ()

        # Run the model on the first frames
        previous_frame_valid_time = None

        while True:
            _, data = self.redis_handle.brpop(self.input_queue)
            frame = pd.read_json(data)
            frame_valid_time = frame['observed_at'][0]
            if previous_frame_valid_time:
                delta_t = frame_valid_time - previous_frame_valid_time
                initial_frame = False
            else:
                delta_t = 0
                initial_frame = True
            locations = self.process_frame(frame, frame_valid_time, delta_t, initial_frame)
            previous_frame_valid_time = frame_valid_time

    def process_frame(self, frame, frame_valid_time, delta_t, initial_frame = False):
        start_time = time.time()
        print("Processing frame %s" % frame_valid_time)
        y_discrete, y_continuous = self.variable_structure.sensor_data_parse_one_timestep(frame)
        if initial_frame:
            self.state = ModelState(*self.sensor_model.generate_initial_particles(y_discrete, y_continuous))
        else:
            self.state = ModelState(*self.sensor_model.generate_next_particles(*self.state, y_discrete, y_continuous, delta_t)[:3])

        x_continuous_mean_particle = np.average(
            self.state.x_continuous_particles,
            axis=0,
            weights=np.repeat(np.exp(self.state.log_weights), self.variable_structure.num_x_continuous_vars).reshape(
                (self.num_particles,
                 self.variable_structure.num_x_continuous_vars)))

        x_continuous_squared_mean_particle = np.average(
            np.square(self.state.x_continuous_particles),
            axis=0,
            weights=np.repeat(np.exp(self.state.log_weights), self.variable_structure.num_x_continuous_vars).reshape(
                (self.num_particles,
                 self.variable_structure.num_x_continuous_vars)))

        x_continuous_sd_particle = np.sqrt(np.abs(x_continuous_squared_mean_particle - np.square(x_continuous_mean_particle)))

        locations = x_continuous_mean_particle.reshape(self.variable_structure.num_moving_sensors, self.variable_structure.num_dimensions)
        std_deviations = x_continuous_sd_particle.reshape(self.variable_structure.num_moving_sensors, self.variable_structure.num_dimensions)
        print("*** processing time: %dms" % (int((time.time() - start_time) * 1000)))
        self.publish_to_firebase(locations, std_deviations, frame_valid_time)
        print("="*80)

    def publish_to_firebase(self, locations, std_deviations, timestamp):
        batch = self.firebase.batch()

        for ((entity_type, entity_id), (x,y), (x_stddev, y_stddev)) in zip(self.entity_ids, locations, std_deviations):
            path = 'classrooms/%s/entity_locations/%s-%s-%s' % (self.classroom_id, entity_type, entity_id, timestamp)
            doc_ref = self.firebase.document(path)
            print("%s %d: (%f, %f)" % (entity_type, entity_id, x, y))
            publish_location = {
                'entityType': u'%s' % entity_type,
                'entityId': entity_id,
                'x': x.item(),
                'y': y.item(),
                'xStdDev': x_stddev.item(),
                'yStdDev': y_stddev.item(),
                'timestamp': timestamp
            }
            batch.set(doc_ref, publish_location)

        batch.commit()

if __name__ == '__main__':

    parser = ArgumentParser()
    parser.add_argument("-c", "--classroom_id", dest="classroom_id", required=True, type=int, help="Classroom ID")
    parser.add_argument("-n", "--num_particles", dest="num_particles", type=int, default=10000, help="Number of particles to use in the model")

    options = parser.parse_args()

    try:
        worker = LocationModelWorker(options.classroom_id, options.num_particles)
        worker.run()
    except ConfigError as error:
        sys.exit(error)
