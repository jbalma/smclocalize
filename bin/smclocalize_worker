#!/usr/bin/env python3
import numpy as np
from argparse import ArgumentParser
import pandas as pd
import redis
import time, os, sys
from collections import namedtuple, defaultdict
from smclocalize import *
import firebase_admin
from firebase_admin import firestore
import pytz
import sensei
import dateutil.parser
from datetime import timedelta, datetime



ModelState = namedtuple("ModelState", "x_discrete_particles x_continuous_particles log_weights")

class ConfigError(ValueError):
    pass


class LocationModelWorker:
    def __init__(self, classroom_id, num_particles):
        self.classroom_id = classroom_id
        self.num_particles = num_particles

        firebase_url = os.getenv('FIREBASE_URL')
        if firebase_url is None:
            raise ConfigError("Missing environment variable FIREBASE_URL. Please see README.")

        credentials_certificate = firebase_admin.credentials.Certificate({
            'private_key': os.getenv('FIREBASE_PRIVATE_KEY', False),
            'client_email': os.getenv('FIREBASE_CLIENT_EMAIL', ''),
            'type': 'service_account',
            'token_uri': 'https://accounts.google.com/o/oauth2/token',
            'project_id': os.getenv('FIREBASE_PROJECT_ID', 'sensei-b9fb6'),
            'private_key_id': os.getenv('FIREBASE_PRIVATE_KEY_ID'),
            'client_id': os.getenv('FIREBASE_CLIENT_ID'),
            'auth_uri': 'https://accounts.google.com/o/oauth2/auth',
            'token_uri': 'https://accounts.google.com/o/oauth2/token',
            'auth_provider_x509_cert_url': 'https://www.googleapis.com/oauth2/v1/certs',
            'client_x509_cert_url': os.getenv('FIREBASE_CLIENT_X509_CERT_URL')
            })
        firebase_admin.initialize_app(credentials_certificate, options={
            'databaseURL': firebase_url
        })
        self.firebase = firebase_admin.firestore.client()

        classroom_doc = self.firebase.document('classrooms/%d' % self.classroom_id)
        classroom_doc_snapshot = classroom_doc.get(['width', 'length', 'timezone'])
        width = classroom_doc_snapshot.get('width')
        length = classroom_doc_snapshot.get('length')
        print("Width from firebase = (width:%s, length:%s)" % (width, length))

        #Room geometry
        room_size = np.array([length, width])
        print("room_size = %s" % room_size)
        room_corners = np.array([[0.0, 0.0], room_size])
        print("room_corners = %s" % room_corners)

        timezone_str = classroom_doc_snapshot.get('timezone')
        self.timezone = pytz.timezone(timezone_str)

        self.sensei_api = sensei.Api(username=os.getenv('SENSEI_USERNAME'), password=os.getenv('SENSEI_PASSWORD'))
        mappings = self.sensei_api.get_sensor_mappings(classroom_id)
        entities = defaultdict(list)
        for mapping in mappings:
            entities[mapping.entity_type.value].append(mapping)

        child_entity_ids = [entity.entity_id for entity in entities['child']]
        material_entity_ids = [entity.entity_id for entity in entities['material']]
        teacher_entity_ids = [entity.entity_id for entity in entities['teacher']]
        area_entity_ids = [entity.entity_id for entity in entities['area']]

        child_sensor_ids = [entity.sensor_id for entity in entities['child']]
        material_sensor_ids = [entity.sensor_id for entity in entities['material']]
        teacher_sensor_ids = [entity.sensor_id for entity in entities['teacher']]
        area_sensor_ids = [entity.sensor_id for entity in entities['area']]
        self.sensor_ids = (
            child_sensor_ids +
            material_sensor_ids +
            teacher_sensor_ids +
            area_sensor_ids)

        print("child_entity_ids = %s" % child_entity_ids)
        print("material_entity_ids = %s" % material_entity_ids)
        print("teacher_entity_ids = %s" % teacher_entity_ids)
        print("area_entity_ids = %s" % area_entity_ids)

        self.entity_ids = (
            [['child', id] for id in child_entity_ids] +
            [['material', id] for id in material_entity_ids] +
            [['teacher', id] for id in teacher_entity_ids] +
            [['area', id] for id in area_entity_ids])

        self.variable_structure = SensorVariableStructure(child_entity_ids,
                                                          material_entity_ids,
                                                          teacher_entity_ids,
                                                          area_entity_ids)

        areas_by_id = {area.entity_id: area for area in self.sensei_api.get_areas(classroom_id)}

        area_positions = []

        room_center = room_size / 2
        for area_id in area_entity_ids:
            area = areas_by_id.get(area_id)
            position = [area.x_position, area.y_position]
            area_positions.append(position)

        fixed_sensor_positions = np.array(area_positions)
        print("fixed_sensor_positions = %s" % fixed_sensor_positions)

        self.sensor_model = SensorModel(
            self.variable_structure,
            room_corners,
            fixed_sensor_positions,
            self.num_particles)


    def run_live(self):
        self.model_state = ()

        redis_url = os.getenv('REDIS_URL')
        if redis_url is None:
            raise ConfigError("Missing environment variable REDIS_URL. Please see README.")
        self.redis_handle = redis.Redis.from_url(redis_url)
        self.input_queue = 'radio_obs_classroom_%d' % self.classroom_id

        previous_frame_valid_time = None

        while True:
            _, data = self.redis_handle.brpop(self.input_queue)
            frame = pd.read_json(data)
            frame_valid_time = frame['observed_at'][0]
            if previous_frame_valid_time:
                delta_t = frame_valid_time - previous_frame_valid_time
                initial_frame = False
            else:
                delta_t = 0
                initial_frame = True
            locations = self.process_frame(frame, frame_valid_time, delta_t, initial_frame)
            previous_frame_valid_time = frame_valid_time

    def run_for_date(self, date_str):
        date = dateutil.parser.parse(date_str)
        date = self.timezone.localize(date)

        self.model_state = ()

        previous_frame_valid_time = None

        # Fetch data in blocks of one hour
        for hour in range(8,17):
            start_time = date.replace(hour=hour, minute=0, second=0, microsecond=0)
            end_time = start_time + timedelta(hours=1) - timedelta(seconds=10)
            obs = self.sensei_api.get_radio_observations(self.classroom_id, start_time=start_time, end_time=end_time, json_rep=True)
            if len(obs) == 0:
                continue
            print("%d obs for %s" % (len(obs), start_time))
            df = pd.DataFrame(obs)
            df['observed_at'] = pd.to_datetime(df['observed_at'])
            timestamps = np.sort(df['observed_at'].unique())
            for frame_valid_time in timestamps:
                frame = df[df['observed_at'] == frame_valid_time]
                if previous_frame_valid_time:
                    delta_t = frame_valid_time - previous_frame_valid_time
                    initial_frame = False
                else:
                    delta_t = 0
                    initial_frame = True
                locations = self.process_frame(frame, pd.Timestamp(frame_valid_time), delta_t, initial_frame)
                previous_frame_valid_time = frame_valid_time

    def process_frame(self, frame, frame_valid_time, delta_t, initial_frame = False):
        start_time = time.time()
        print("Processing frame %s" % frame_valid_time)
        y_discrete, y_continuous = self.variable_structure.parse_ping_data(frame)
        if initial_frame:
            self.state = ModelState(*self.sensor_model.generate_initial_particles(y_discrete, y_continuous))
        else:
            self.state = ModelState(*self.sensor_model.generate_next_particles(*self.state, y_discrete, y_continuous, delta_t)[:3])

        x_continuous_mean_particle = np.average(
            self.state.x_continuous_particles,
            axis=0,
            weights=np.repeat(np.exp(self.state.log_weights), self.variable_structure.num_x_continuous_vars).reshape(
                (self.num_particles,
                 self.variable_structure.num_x_continuous_vars)))

        x_continuous_squared_mean_particle = np.average(
            np.square(self.state.x_continuous_particles),
            axis=0,
            weights=np.repeat(np.exp(self.state.log_weights), self.variable_structure.num_x_continuous_vars).reshape(
                (self.num_particles,
                 self.variable_structure.num_x_continuous_vars)))

        x_continuous_sd_particle = np.sqrt(np.abs(x_continuous_squared_mean_particle - np.square(x_continuous_mean_particle)))

        locations = x_continuous_mean_particle.reshape(self.variable_structure.num_moving_sensors, self.variable_structure.num_dimensions)
        std_deviations = x_continuous_sd_particle.reshape(self.variable_structure.num_moving_sensors, self.variable_structure.num_dimensions)
        print("*** processing time: %dms" % (int((time.time() - start_time) * 1000)))
        self.publish_to_firebase(locations, std_deviations, frame_valid_time)
        print("="*80)

    def publish_to_firebase(self, locations, std_deviations, timestamp):
        batch = self.firebase.batch()

        for ((entity_type, entity_id), sensor_id, (x,y), (x_stddev, y_stddev)) in zip(self.entity_ids, self.sensor_ids, locations, std_deviations):
            path = 'classrooms/%s/entity_locations/%s-%s-%s' % (self.classroom_id, entity_type, entity_id, timestamp)
            doc_ref = self.firebase.document(path)
            print("%s %d (%d): (%f, %f)" % (entity_type, entity_id, sensor_id, x, y))
            publish_location = {
                'entityType': u'%s' % entity_type,
                'entityId': entity_id,
                'x': x.item(),
                'y': y.item(),
                'xStdDev': x_stddev.item(),
                'yStdDev': y_stddev.item(),
                'timestamp': timestamp
            }
            batch.set(doc_ref, publish_location)

        batch.commit()

if __name__ == '__main__':

    parser = ArgumentParser()
    parser.add_argument("-c", "--classroom_id", dest="classroom_id", required=True, type=int, help="Classroom ID")
    parser.add_argument("-d", "--date", dest="date", type=str, help="If specified, model will run for given date")
    parser.add_argument("-n", "--num_particles", dest="num_particles", type=int, default=10000, help="Number of particles to use in the model")

    options = parser.parse_args()

    try:
        worker = LocationModelWorker(options.classroom_id, options.num_particles)
        if options.date:
            worker.run_for_date(options.date)
        else:
            worker.run_live()
    except ConfigError as error:
        sys.exit(error)
